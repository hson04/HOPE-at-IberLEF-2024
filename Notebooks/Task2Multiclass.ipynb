{"cells":[{"cell_type":"code","execution_count":null,"id":"89d3e716","metadata":{},"outputs":[],"source":["!pip install tweet-preprocessor"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-03-28T17:31:55.407013Z","iopub.status.busy":"2024-03-28T17:31:55.405925Z","iopub.status.idle":"2024-03-28T17:31:56.465277Z","shell.execute_reply":"2024-03-28T17:31:56.464314Z","shell.execute_reply.started":"2024-03-28T17:31:55.406974Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import re, string\n","import numpy as np"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-03-28T17:31:56.467667Z","iopub.status.busy":"2024-03-28T17:31:56.467283Z","iopub.status.idle":"2024-03-28T17:32:00.471535Z","shell.execute_reply":"2024-03-28T17:32:00.470152Z","shell.execute_reply.started":"2024-03-28T17:31:56.467641Z"},"trusted":true},"outputs":[],"source":["import random, torch\n","\n","def set_seed(seed):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    if torch.cuda.is_available():\n","        torch.cuda.manual_seed_all(seed)\n","\n","set_seed(42)"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-03-28T17:32:00.473482Z","iopub.status.busy":"2024-03-28T17:32:00.472960Z","iopub.status.idle":"2024-03-28T17:32:00.481292Z","shell.execute_reply":"2024-03-28T17:32:00.480421Z","shell.execute_reply.started":"2024-03-28T17:32:00.473448Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'cuda:0'"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["import torch\n","device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n","device"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-03-28T17:32:00.483711Z","iopub.status.busy":"2024-03-28T17:32:00.483020Z","iopub.status.idle":"2024-03-28T17:32:00.500968Z","shell.execute_reply":"2024-03-28T17:32:00.499936Z","shell.execute_reply.started":"2024-03-28T17:32:00.483673Z"},"trusted":true},"outputs":[],"source":["path_train = \"/kaggle/input/hope-task-2-english/Task 2 Training set (English).csv\"\n","path_val = \"/kaggle/input/hope-task-2-english/val.csv\""]},{"cell_type":"markdown","metadata":{},"source":["# Read dataset"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-03-28T17:32:00.504572Z","iopub.status.busy":"2024-03-28T17:32:00.504187Z","iopub.status.idle":"2024-03-28T17:32:00.560588Z","shell.execute_reply":"2024-03-28T17:32:00.559647Z","shell.execute_reply.started":"2024-03-28T17:32:00.504541Z"},"trusted":true},"outputs":[],"source":["import string,re\n","def preprocessing_text(text):\n","    text = p.clean(text)\n","\n","    text = text.strip()\n","    text = text.translate(text.maketrans('', '', string.punctuation.replace(\"_\",\"\")))\n","    text = re.sub('\\\\s+',' ',text).strip()\n","    return text"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-03-28T17:32:00.562192Z","iopub.status.busy":"2024-03-28T17:32:00.561846Z","iopub.status.idle":"2024-03-28T17:32:03.645418Z","shell.execute_reply":"2024-03-28T17:32:03.644374Z","shell.execute_reply.started":"2024-03-28T17:32:00.562158Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["6192 6192\n","1032 1032\n"]}],"source":["import pandas as pd\n","\n","def convert_label(text):\n","    if text == \"Not Hope\":\n","        return 0\n","    elif text == \"Generalized Hope\":\n","        return 1\n","    elif text == \"Unrealistic Hope\":\n","        return 2\n","    elif text == \"Realistic Hope\":\n","        return 3\n","    else:\n","        print(\"Error: \", text)\n","        return 0\n","    \n","\n","def read_and_preprocessing(path_data):\n","    df = pd.read_csv(path_data)\n","    df[\"multiclass\"] = df[\"multiclass\"].apply(convert_label)\n","    x_input = df[\"text\"].apply(preprocessing_text).tolist()\n","    y_output = df[\"multiclass\"].tolist()\n","    ids = df[\"id\"].tolist()\n","    return x_input,y_output,ids\n","\n","train_texts, train_labels,train_ids = read_and_preprocessing(path_train)\n","valid_texts,valid_labels,valid_ids = read_and_preprocessing(path_val)\n","print(len(train_texts),len(train_labels))\n","print(len(valid_texts),len(valid_labels))"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-03-28T17:32:03.647101Z","iopub.status.busy":"2024-03-28T17:32:03.646793Z","iopub.status.idle":"2024-03-28T17:32:03.667145Z","shell.execute_reply":"2024-03-28T17:32:03.666027Z","shell.execute_reply.started":"2024-03-28T17:32:03.647076Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>x_data</th>\n","      <th>y_output</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>im really liking this project lets work togeth...</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>oh shit really i would hope theyd shed some mo...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>good morning bud smiling face with hearts anot...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>i aspire to have the level of delusion to beli...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>projects are continuously attacked by hackers ...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                              x_data  y_output\n","0  im really liking this project lets work togeth...         3\n","1  oh shit really i would hope theyd shed some mo...         1\n","2  good morning bud smiling face with hearts anot...         1\n","3  i aspire to have the level of delusion to beli...         2\n","4  projects are continuously attacked by hackers ...         0"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["df_train = pd.DataFrame(list(zip(train_texts, train_labels)),\n","               columns =['x_data', 'y_output'])\n","df_train.head()"]},{"cell_type":"markdown","metadata":{},"source":["# Build Filter Classifier"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-28T17:32:03.668898Z","iopub.status.busy":"2024-03-28T17:32:03.668513Z","iopub.status.idle":"2024-03-28T17:33:21.158336Z","shell.execute_reply":"2024-03-28T17:33:21.157097Z","shell.execute_reply.started":"2024-03-28T17:32:03.668868Z"},"trusted":true},"outputs":[],"source":["import torch\n","from transformers import AutoModelForSequenceClassification, AutoTokenizer\n","\n","model_name = \"microsoft/deberta-v3-base\" #Try different models here \n","\n","bert_model = AutoModelForSequenceClassification.from_pretrained(model_name,num_labels=4)\n","tokenizer = AutoTokenizer.from_pretrained(model_name, model_max_length=512)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-03-28T17:33:21.161269Z","iopub.status.busy":"2024-03-28T17:33:21.159853Z","iopub.status.idle":"2024-03-28T17:33:21.730159Z","shell.execute_reply":"2024-03-28T17:33:21.729095Z","shell.execute_reply.started":"2024-03-28T17:33:21.161229Z"},"trusted":true},"outputs":[],"source":["max_length = 512\n","train_encodings = tokenizer(train_texts, truncation=True, max_length=max_length, padding=True)"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-03-28T17:33:21.732073Z","iopub.status.busy":"2024-03-28T17:33:21.731732Z","iopub.status.idle":"2024-03-28T17:33:23.960417Z","shell.execute_reply":"2024-03-28T17:33:23.959208Z","shell.execute_reply.started":"2024-03-28T17:33:21.732040Z"},"trusted":true},"outputs":[],"source":["import torch\n","\n","class CustomDataset(torch.utils.data.Dataset):\n","    def __init__(self, encodings, labels):\n","        self.encodings = encodings\n","        self.labels = labels\n","\n","    def __getitem__(self, idx):\n","        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","        item['labels'] = torch.tensor(self.labels[idx])\n","        return item\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","train_dataset = CustomDataset(train_encodings, train_labels)"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-03-28T17:33:23.962274Z","iopub.status.busy":"2024-03-28T17:33:23.961900Z","iopub.status.idle":"2024-03-28T17:34:43.160712Z","shell.execute_reply":"2024-03-28T17:34:43.158342Z","shell.execute_reply.started":"2024-03-28T17:33:23.962243Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-03-28 17:33:26.844921: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-03-28 17:33:26.845040: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-03-28 17:33:26.959196: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n","dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"]},{"name":"stdout","output_type":"stream","text":["  ········································\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"data":{"text/html":["wandb version 0.16.5 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.16.4"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20240328_173358-lzcasl36</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/shen-long/huggingface/runs/lzcasl36' target=\"_blank\">youthful-meadow-71</a></strong> to <a href='https://wandb.ai/shen-long/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/shen-long/huggingface' target=\"_blank\">https://wandb.ai/shen-long/huggingface</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/shen-long/huggingface/runs/lzcasl36' target=\"_blank\">https://wandb.ai/shen-long/huggingface/runs/lzcasl36</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='7' max='1940' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [   7/1940 00:07 < 46:34, 0.69 it/s, Epoch 0.03/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 978.00 MiB. GPU 0 has a total capacty of 15.89 GiB of which 270.12 MiB is free. Process 2324 has 15.63 GiB memory in use. Of the allocated memory 7.44 GiB is allocated by PyTorch, and 7.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","Cell \u001b[0;32mIn[11], line 20\u001b[0m\n\u001b[1;32m      3\u001b[0m training_args \u001b[38;5;241m=\u001b[39m TrainingArguments(\n\u001b[1;32m      4\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./results\u001b[39m\u001b[38;5;124m'\u001b[39m,          \u001b[38;5;66;03m# output directory\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     num_train_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,              \u001b[38;5;66;03m# total number of training epochs\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m     save_total_limit \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     13\u001b[0m )\n\u001b[1;32m     15\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     16\u001b[0m     model\u001b[38;5;241m=\u001b[39mbert_model,                         \u001b[38;5;66;03m# the instantiated 🤗 Transformers model to be trained\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,                  \u001b[38;5;66;03m# training arguments, defined above\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39mtrain_dataset,         \u001b[38;5;66;03m# training dataset\u001b[39;00m\n\u001b[1;32m     19\u001b[0m )\n\u001b[0;32m---> 20\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# API: fac85ccacc3dffb183116aba932e6bcc08010443\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:1624\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1622\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1623\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1624\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1625\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1626\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1627\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1628\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1629\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:1961\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1958\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   1960\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 1961\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1963\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1964\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1965\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1966\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1967\u001b[0m ):\n\u001b[1;32m   1968\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1969\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2911\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2909\u001b[0m         scaled_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m   2910\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2911\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2913\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach() \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:2001\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   1999\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   2000\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2001\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 978.00 MiB. GPU 0 has a total capacty of 15.89 GiB of which 270.12 MiB is free. Process 2324 has 15.63 GiB memory in use. Of the allocated memory 7.44 GiB is allocated by PyTorch, and 7.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"]}],"source":["from transformers import Trainer, TrainingArguments\n","\n","training_args = TrainingArguments(\n","    output_dir='./results',          # output directory\n","    num_train_epochs=10,              # total number of training epochs\n","    learning_rate=5e-5,\n","    per_device_train_batch_size=32,  # batch size per device during training\n","    warmup_steps=100,                # number of warmup steps for learning rate scheduler\n","    weight_decay=0.01,               # strength of weight decay\n","    logging_dir='./logs',            # directory for storing logs\n","    logging_steps=100,\n","    save_total_limit = 1\n",")\n"," \n","trainer = Trainer(\n","    model=bert_model,                         # the instantiated 🤗 Transformers model to be trained\n","    args=training_args,                  # training arguments, defined above\n","    train_dataset=train_dataset,         # training dataset\n",")\n","trainer.train()\n","# API: fac85ccacc3dffb183116aba932e6bcc08010443"]},{"cell_type":"markdown","metadata":{},"source":["# Inference"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-03-28T17:34:43.161553Z","iopub.status.idle":"2024-03-28T17:34:43.161889Z","shell.execute_reply":"2024-03-28T17:34:43.161739Z","shell.execute_reply.started":"2024-03-28T17:34:43.161725Z"},"trusted":true},"outputs":[],"source":["def make_prediction(review,tokenizer,trainer):\n","    demo_input = preprocessing_text(review)\n","    demo_encodings = tokenizer([demo_input], truncation=True, max_length = max_length, padding=True)\n","    test_dataset = CustomDataset(demo_encodings, [0])\n","    predic_demo = trainer.predict(test_dataset)[0]\n","    predict_label = np.argmax(predic_demo, axis=1).flatten().tolist()[0]\n","    return predict_label"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-03-28T17:34:43.163289Z","iopub.status.idle":"2024-03-28T17:34:43.163746Z","shell.execute_reply":"2024-03-28T17:34:43.163518Z","shell.execute_reply.started":"2024-03-28T17:34:43.163501Z"},"trusted":true},"outputs":[],"source":["y_pred = []\n","\n","for review in valid_texts:\n","    a = make_prediction(review,tokenizer,trainer)\n","    y_pred.append(a)\n","print(y_pred[:10])\n","print(valid_labels[:10])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-03-28T17:34:43.165089Z","iopub.status.idle":"2024-03-28T17:34:43.165553Z","shell.execute_reply":"2024-03-28T17:34:43.165340Z","shell.execute_reply.started":"2024-03-28T17:34:43.165322Z"},"trusted":true},"outputs":[],"source":["from sklearn.metrics import *\n","\n","print(\"M_Pr: \", round(precision_score(valid_labels, y_pred, average='macro'),4))\n","print(\"M_Re: \", round(recall_score(valid_labels, y_pred, average='macro'),4))\n","print(\"M_F1: \", round(f1_score(valid_labels, y_pred, average='macro'),4))\n","\n","print(\"W_Pr: \", round(precision_score(valid_labels, y_pred, average='weighted'),4))\n","print(\"W_Re: \", round(recall_score(valid_labels, y_pred, average='weighted'),4))\n","print(\"W_F1: \", round(f1_score(valid_labels, y_pred, average='weighted'),4))\n","\n","print(\"acc:\", round(accuracy_score(valid_labels, y_pred), 4))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-03-28T17:34:43.167046Z","iopub.status.idle":"2024-03-28T17:34:43.167510Z","shell.execute_reply":"2024-03-28T17:34:43.167301Z","shell.execute_reply.started":"2024-03-28T17:34:43.167282Z"},"trusted":true},"outputs":[],"source":["from sklearn.metrics import classification_report\n","print(classification_report(valid_labels, y_pred))"]},{"cell_type":"markdown","metadata":{},"source":["# Submission for Validation datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-03-28T17:34:43.168792Z","iopub.status.idle":"2024-03-28T17:34:43.169245Z","shell.execute_reply":"2024-03-28T17:34:43.169020Z","shell.execute_reply.started":"2024-03-28T17:34:43.169003Z"},"trusted":true},"outputs":[],"source":["# def convert2category(y_pred):\n","#     y_label = []\n","#     for y in y_pred:\n","#         if y == 0:\n","#               y_label.append(\"Not Hope\")\n","#         elif y == 1:\n","#               y_label.append(\"Generalized Hope\")\n","#         elif y == 2:\n","#               y_label.append(\"Unrealistic Hope\")\n","#         elif y == 3:\n","#               y_label.append(\"Realistic Hope\")\n","#     return y_label"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-03-28T17:34:43.170286Z","iopub.status.idle":"2024-03-28T17:34:43.170709Z","shell.execute_reply":"2024-03-28T17:34:43.170507Z","shell.execute_reply.started":"2024-03-28T17:34:43.170489Z"},"trusted":true},"outputs":[],"source":["# name_sub = \"predictions.csv\"\n","# y_pred_label = convert2category(y_pred)\n","# df_sub = pd.DataFrame(list(zip(valid_ids, y_pred_label)),\n","#                columns =['id', 'category'])\n","# df_sub.to_csv(name_sub)\n","# df_sub.head()"]},{"cell_type":"markdown","id":"a225c842","metadata":{},"source":["# Submission for Test datasets"]},{"cell_type":"code","execution_count":null,"id":"02f7076f","metadata":{},"outputs":[],"source":["def read_and_preprocessing_for_test(path_data):\n","    df = pd.read_csv(path_data)\n","    x_input = df[\"text\"].apply(preprocessing_text).tolist()\n","    ids = df[\"id\"].tolist()\n","    return x_input,ids\n","\n","test_texts,test_ids = read_and_preprocessing_for_test(path_test)\n","print(len(test_texts))\n","\n","def make_prediction(review,tokenizer,trainer):\n","    demo_input = preprocessing_text(review)\n","    demo_encodings = tokenizer([demo_input], truncation=True, max_length = max_length, padding=True)\n","    test_dataset = CustomDataset(demo_encodings, [0])\n","    predic_demo = trainer.predict(test_dataset)[0]\n","    predict_label = np.argmax(predic_demo, axis=1).flatten().tolist()[0]\n","    return predict_label"]},{"cell_type":"code","execution_count":null,"id":"f0706eea","metadata":{},"outputs":[],"source":["y_pred_test = []\n","\n","for review in test_texts:\n","    a = make_prediction(review,tokenizer,trainer)\n","    y_pred_test.append(a)"]},{"cell_type":"code","execution_count":null,"id":"929534fc","metadata":{},"outputs":[],"source":["def convert2category(y_pred):\n","    y_label = []\n","    for y in y_pred:\n","        if y == 0:\n","              y_label.append(\"Not Hope\")\n","        else:\n","              y_label.append(\"Hope\")\n","    return y_label"]},{"cell_type":"code","execution_count":null,"id":"ad496f2b","metadata":{},"outputs":[],"source":["name_sub = \"predictions.csv\"\n","y_pred_label = convert2category(y_pred_test)\n","df_sub = pd.DataFrame(list(zip(test_ids, y_pred_label)),\n","               columns =['id', 'category'])\n","df_sub.to_csv(name_sub)\n","df_sub.head()"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30674,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"}},"nbformat":4,"nbformat_minor":5}
